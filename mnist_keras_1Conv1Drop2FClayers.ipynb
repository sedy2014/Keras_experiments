{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset,with keras and Sequential model with Conv,dropout,2 FC layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "# set image dimension for Conv layer etc based on tensor flow or theano\n",
    "K.set_image_dim_ordering('tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load (downloaded if needed to : C:\\Users\\sidha\\.keras\\datasets\\mnist.npz) the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape) # X_train.shape result is a tuple\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "# number of training samples\n",
    "N1 = X_train.shape[0]  # same as  N1= X_train.shape and then N1 = N1[0]\n",
    "N2 = X_test.shape[0]  \n",
    "h = X_train.shape[1]\n",
    "w = X_train.shape[2]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the shape of data\n",
    "print(X_train[0].shape)\n",
    "print(X_test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create CNN with lots of layers\n",
    "num_pixels = h*w\n",
    "# reshape N1 samples to 4-D tensor\n",
    "x_train = X_train.reshape(N1,w,h,1).astype('float32') # shape is now (60000,28,28,1)\n",
    "x_test = X_test.reshape(N2,w,h,1).astype('float32') # shape is now (10000,784)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finally, the output variable is an integer from 0 to 9. This is a multi-class classification problem. 10 digits \n",
    "# classified to 10 classes\n",
    "#As such, it is good practice to use a one hot encoding of the class values,\n",
    "#transforming the vector of class integers into a binary matrix.\n",
    "\n",
    "#We can easily do this using the built-in np_utils.to_categorical() helper function in Keras.\n",
    "y_train = np_utils.to_categorical(y_train)\n",
    "y_test = np_utils.to_categorical(y_test) # This is now tuple (10000,10): 10000 lables for 10 classes\n",
    "num_classes = y_test.shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test[0]  # now, digit N is being repesented as [0 0 .. 1 ..0] where 1 is at index N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_model():\n",
    "    #create model\n",
    "    model = Sequential()\n",
    "    #Convolutional layer with 30 feature maps of size 5Ã—5. 30 filters of size 5 by 5\n",
    "    model.add(Conv2D(30, (5, 5), input_shape=(w, h,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(15, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    # drop 20% of input units\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    #Fully connected layer with 128 neurons and RELU activation\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    # op layer\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = conv_model()\n",
    "# Train the model\n",
    "# test data is used ad validation data\n",
    "#  A verbose value of 2 is used to reduce the output to one line for each training epoch.\n",
    "#model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=10, batch_size=200, verbose=2)\n",
    "trn_acc = model.fit(x_train, y_train, validation_split=0.15, epochs=10, batch_size=200, verbose=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final evaluation of the model on test data\n",
    "scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Baseline Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "print(\"Baseline Error: %.2f%%\" % (100-scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot training accuracy and loss\n",
    "trn_acc = trn.history['acc']\n",
    "trn_loss = trn.history['loss']\n",
    "epochs = range(len(trn_acc))\n",
    "plt.plot(epochs,trn_acc,'bo',label = 'Train accuracy')\n",
    "plt.plot(epochs,trn_loss,'b',label = 'Train Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot validation accuracy and loss\n",
    "val_acc = trn.history['val_acc']\n",
    "val_loss = trn.history['val_loss']\n",
    "epochs = range(len(trn_acc))\n",
    "plt.plot(epochs,val_acc,'bo',label = 'Train accuracy')\n",
    "plt.plot(epochs,val_loss,'b',label = 'Train Loss')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
